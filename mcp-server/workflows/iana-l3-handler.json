{
  "name": "iana-l3-handler",
  "nodes": [
    {
      "parameters": {
        "jsCode": "// L3 Handler: Expert analysis with RAG context (required)\n// Input: { query, rag_context, rag_count, user_id, channel, conversation_id }\nconst input = $input.first().json;\n\nif (!input.rag_context || input.rag_count === 0) {\n  return [{\n    json: {\n      error: 'L3 handler requires RAG context',\n      tier: 'L3',\n      query: input.query\n    }\n  }];\n}\n\nreturn [{\n  json: {\n    query: input.query,\n    rag_context: input.rag_context,\n    rag_count: input.rag_count,\n    user_id: input.user_id,\n    channel: input.channel,\n    conversation_id: input.conversation_id,\n    tier: 'L3',\n    handler: 'l3-expert-analysis'\n  }\n}];"
      },
      "id": "parse-input",
      "name": "Parse Input",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [240, 300]
    },
    {
      "parameters": {
        "jsCode": "// Prepare CLI command for L3\nconst parseData = $('Parse Input').first().json;\nconst query = parseData.query || '';\nconst ragContext = parseData.rag_context || '';\n\nconst prompt = `${ragContext}You are an expert AI assistant with deep knowledge of the ALFA system.\\n\\nQuery: ${query}\\n\\nUsing the RAG context provided above, provide a comprehensive, detailed analysis. Be thorough, cite specific information from the context when relevant, and provide actionable insights.\\n\\nStructure your response:\\n1. Summary of the query\\n2. Key findings from the context\\n3. Detailed analysis\\n4. Recommendations or next steps`;\nconst escapedPrompt = prompt.replace(/\"/g, '\\\\\"').replace(/\\$/g, '\\\\$');\n\nreturn [{\n  json: {\n    command: `node /Users/arnaud/Documents/ALFA-Agent-Method/alfa-dashboard/scripts/llm-cli-wrapper.js cursor-agent \"${escapedPrompt}\" claude-3-5-sonnet`,\n    prompt: prompt\n  }\n}];"
      },
      "id": "prepare-command",
      "name": "Prepare Command",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [460, 300]
    },
    {
      "parameters": {
        "jsCode": "// Execute CLI wrapper via child_process\nconst { execSync } = require('child_process');\nconst command = $input.first().json.command || '';\n\ntry {\n  const result = execSync(command, {\n    encoding: 'utf8',\n    maxBuffer: 10 * 1024 * 1024,\n    timeout: 60000\n  });\n  \n  // Parse JSON response\n  let cliResponse;\n  try {\n    cliResponse = JSON.parse(result.trim());\n  } catch (e) {\n    cliResponse = { response: result.trim(), error: 'JSON parse failed' };\n  }\n  \n  return [{\n    json: {\n      stdout: result.trim(),\n      stderr: '',\n      ...cliResponse\n    }\n  }];\n} catch (error) {\n  return [{\n    json: {\n      stdout: '',\n      stderr: error.message,\n      error: error.message\n    }\n  }];\n}"
      },
      "id": "llm-expert",
      "name": "LLM Expert (CLI)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [680, 300]
    },
    {
      "parameters": {
        "jsCode": "// Format L3 response (from CLI)\nconst input = $input.first().json;\nconst parseData = $('Parse Input').first().json;\n\nif (input.error) {\n  return [{\n    json: {\n      tier: 'L3',\n      response: `Error: ${input.error}. L3 handler requires RAG context.`,\n      query: parseData.query,\n      rag_count: 0,\n      handler: 'l3-expert-analysis'\n    }\n  }];\n}\n\n// Extract response from CLI output\nlet cliResponse;\ntry {\n  const cliOutput = input.stdout || input.stderr || '{}';\n  cliResponse = JSON.parse(cliOutput.trim());\n} catch (e) {\n  cliResponse = { response: input.stdout || input.stderr || 'No response' };\n}\n\nconst llmResponse = cliResponse.response || cliResponse.text || '';\n\nreturn [{\n  json: {\n    tier: 'L3',\n    response: llmResponse,\n    query: parseData.query,\n    rag_count: parseData.rag_count,\n    user_id: parseData.user_id,\n    channel: parseData.channel,\n    conversation_id: parseData.conversation_id,\n    handler: 'l3-expert-analysis',\n    latency_ms: Date.now() - (parseData._meta?.startTime || Date.now())\n  }\n}];"
      },
      "id": "format-response",
      "name": "Format Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [900, 300]
    }
  ],
  "connections": {
    "Parse Input": {
      "main": [
        [
          {
            "node": "Prepare Command",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Command": {
      "main": [
        [
          {
            "node": "LLM Expert (CLI)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Expert (CLI)": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "active": false,
  "tags": [
    {
      "name": "IANA"
    },
    {
      "name": "L3"
    }
  ]
}
